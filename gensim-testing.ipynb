{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "model = LdaModel(common_corpus, 5, common_dictionary)\n",
    "cm = CoherenceModel(model=model, corpus=common_corpus, coherence='u_mass')\n",
    "coherence = cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x19e9f7458c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.coherencemodel.CoherenceModel at 0x19e9f745f88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.679371186797123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'computer',\n",
       " 1: 'human',\n",
       " 2: 'interface',\n",
       " 3: 'response',\n",
       " 4: 'survey',\n",
       " 5: 'system',\n",
       " 6: 'time',\n",
       " 7: 'user',\n",
       " 8: 'eps',\n",
       " 9: 'trees',\n",
       " 10: 'graph',\n",
       " 11: 'minors'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(1, 1), (5, 2), (8, 1)],\n",
       " [(3, 1), (6, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(4, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Gensim Core Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"Human machine interface for lab abc computer applications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = [    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = set('for a of the and to in'.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in text_corpus]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'human': 2,\n",
       "             'machine': 1,\n",
       "             'interface': 2,\n",
       "             'lab': 1,\n",
       "             'abc': 1,\n",
       "             'computer': 2,\n",
       "             'applications': 1,\n",
       "             'survey': 2,\n",
       "             'user': 3,\n",
       "             'opinion': 1,\n",
       "             'system': 4,\n",
       "             'response': 2,\n",
       "             'time': 2,\n",
       "             'eps': 2,\n",
       "             'management': 1,\n",
       "             'engineering': 1,\n",
       "             'testing': 1,\n",
       "             'relation': 1,\n",
       "             'perceived': 1,\n",
       "             'error': 1,\n",
       "             'measurement': 1,\n",
       "             'generation': 1,\n",
       "             'random': 1,\n",
       "             'binary': 1,\n",
       "             'unordered': 1,\n",
       "             'trees': 3,\n",
       "             'intersection': 1,\n",
       "             'graph': 3,\n",
       "             'paths': 1,\n",
       "             'minors': 2,\n",
       "             'iv': 1,\n",
       "             'widths': 1,\n",
       "             'well': 1,\n",
       "             'quasi': 1,\n",
       "             'ordering': 1})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Word Frequencies\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "# Associate each word with a unique integer ID\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 0,\n",
       " 'human': 1,\n",
       " 'interface': 2,\n",
       " 'response': 3,\n",
       " 'survey': 4,\n",
       " 'system': 5,\n",
       " 'time': 6,\n",
       " 'user': 7,\n",
       " 'eps': 8,\n",
       " 'trees': 9,\n",
       " 'graph': 10,\n",
       " 'minors': 11}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc  = \"Human Computer Interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(1, 1), (5, 2), (8, 1)],\n",
       " [(3, 1), (6, 1), (7, 1)],\n",
       " [(9, 1)],\n",
       " [(9, 1), (10, 1)],\n",
       " [(9, 1), (10, 1), (11, 1)],\n",
       " [(4, 1), (10, 1), (11, 1)]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.5898341626740045), (11, 0.8075244024440723)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "words = 'system minors'.lower().split()\n",
    "tfidf[dictionary.doc2bow(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "# Index the entire corpus\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=len(dictionary))\n",
    "# list(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0),\n",
       " (1, 0.32448703),\n",
       " (2, 0.41707572),\n",
       " (3, 0.7184812),\n",
       " (4, 0.0),\n",
       " (5, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0),\n",
       " (8, 0.0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_doc = 'system engineering'.split()\n",
    "query_bow = dictionary.doc2bow(query_doc)\n",
    "sims = index[tfidf[query_bow]]\n",
    "list(enumerate(sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.7184812),\n",
       " (2, 0.41707572),\n",
       " (1, 0.32448703),\n",
       " (0, 0.0),\n",
       " (4, 0.0),\n",
       " (5, 0.0),\n",
       " (6, 0.0),\n",
       " (7, 0.0),\n",
       " (8, 0.0)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our document is most similar to document 3 by tfidf similarity score\n",
    "sorted(enumerate(sims), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Corpora and Vector Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint  # pretty-printer\n",
    "from collections import defaultdict\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Had to skip some stuff since links were broken to mycorpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 1, 7, 7, 8],\n",
       "       [8, 1, 4, 3, 5]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "numpy_matrix = np.random.randint(10, size=[5, 2])  # random matrix as an example\n",
    "corpus = gensim.matutils.Dense2Corpus(numpy_matrix)\n",
    "corpus.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<gensim.matutils.Sparse2Corpus object at 0x0000019EA25B92C8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<0x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell might also be broken\n",
    "import scipy\n",
    "scipy_sparse_matrix = scipy.sparse.random(10, 2)  # random sparse matrix as example\n",
    "print(scipy_sparse_matrix)\n",
    "corpus = gensim.matutils.Sparse2Corpus(scipy_sparse_matrix)\n",
    "print(corpus)\n",
    "scipy_csc_matrix = gensim.matutils.corpus2csc(corpus)\n",
    "scipy_csc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Topic and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 19:43:09,994 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-01 19:43:09,995 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora\n",
    "\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)],\n",
      " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
      " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
      " [(1, 1), (5, 2), (8, 1)],\n",
      " [(3, 1), (6, 1), (7, 1)],\n",
      " [(9, 1)],\n",
      " [(9, 1), (10, 1)],\n",
      " [(9, 1), (10, 1), (11, 1)],\n",
      " [(4, 1), (10, 1), (11, 1)]]\n",
      "{0: 'computer',\n",
      " 1: 'human',\n",
      " 2: 'interface',\n",
      " 3: 'response',\n",
      " 4: 'survey',\n",
      " 5: 'system',\n",
      " 6: 'time',\n",
      " 7: 'user',\n",
      " 8: 'eps',\n",
      " 9: 'trees',\n",
      " 10: 'graph',\n",
      " 11: 'minors'}\n"
     ]
    }
   ],
   "source": [
    "pprint(corpus)\n",
    "pprint(dict(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 19:45:54,576 : INFO : collecting document frequencies\n",
      "2020-04-01 19:45:54,577 : INFO : PROGRESS: processing document #0\n",
      "2020-04-01 19:45:54,578 : INFO : calculating IDF weights for 9 documents and 12 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7071067811865476), (1, 0.7071067811865476)]\n"
     ]
    }
   ],
   "source": [
    "doc_bow = [(0, 1), (1, 1)]\n",
    "print(tfidf[doc_bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 19:52:55,397 : INFO : storing corpus in Matrix Market format to corpus.mm\n",
      "2020-04-01 19:52:55,398 : INFO : saving sparse matrix to corpus.mm\n",
      "2020-04-01 19:52:55,399 : INFO : PROGRESS: saving document #0\n",
      "2020-04-01 19:52:55,400 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
      "2020-04-01 19:52:55,401 : INFO : saving MmCorpus index to corpus.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "corpora.MmCorpus.serialize('corpus.mm', corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 19:54:03,811 : INFO : loaded corpus index from corpus.mm.index\n",
      "2020-04-01 19:54:03,811 : INFO : initializing cython corpus reader from corpus.mm\n",
      "2020-04-01 19:54:03,812 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)],\n",
       " [(0, 0.44424552527467476),\n",
       "  (3, 0.44424552527467476),\n",
       "  (4, 0.44424552527467476),\n",
       "  (5, 0.3244870206138555),\n",
       "  (6, 0.44424552527467476),\n",
       "  (7, 0.3244870206138555)],\n",
       " [(2, 0.5710059809418182),\n",
       "  (5, 0.4170757362022777),\n",
       "  (7, 0.4170757362022777),\n",
       "  (8, 0.5710059809418182)],\n",
       " [(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)],\n",
       " [(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)],\n",
       " [(9, 1.0)],\n",
       " [(9, 0.7071067811865475), (10, 0.7071067811865475)],\n",
       " [(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)],\n",
       " [(4, 0.6282580468670046),\n",
       "  (10, 0.45889394536615247),\n",
       "  (11, 0.6282580468670046)]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_loaded = corpora.MmCorpus('corpus.mm')\n",
    "list(corpus_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)],\n",
       " [(0, 0.44424552527467476),\n",
       "  (3, 0.44424552527467476),\n",
       "  (4, 0.44424552527467476),\n",
       "  (5, 0.3244870206138555),\n",
       "  (6, 0.44424552527467476),\n",
       "  (7, 0.3244870206138555)],\n",
       " [(2, 0.5710059809418182),\n",
       "  (5, 0.4170757362022777),\n",
       "  (7, 0.4170757362022777),\n",
       "  (8, 0.5710059809418182)],\n",
       " [(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)],\n",
       " [(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)],\n",
       " [(9, 1.0)],\n",
       " [(9, 0.7071067811865475), (10, 0.7071067811865475)],\n",
       " [(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)],\n",
       " [(4, 0.6282580468670046),\n",
       "  (10, 0.45889394536615247),\n",
       "  (11, 0.6282580468670046)]]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 19:56:17,358 : INFO : using serial LSI version on this node\n",
      "2020-04-01 19:56:17,359 : INFO : updating model with new documents\n",
      "2020-04-01 19:56:17,360 : INFO : preparing a new chunk of documents\n",
      "2020-04-01 19:56:17,360 : INFO : using 100 extra samples and 2 power iterations\n",
      "2020-04-01 19:56:17,361 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2020-04-01 19:56:17,363 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2020-04-01 19:56:17,449 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2020-04-01 19:56:17,454 : INFO : computing the final decomposition\n",
      "2020-04-01 19:56:17,455 : INFO : keeping 2 factors (discarding 47.565% of energy spectrum)\n",
      "2020-04-01 19:56:17,460 : INFO : processed documents up to #9\n",
      "2020-04-01 19:56:17,461 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "2020-04-01 19:56:17,462 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    }
   ],
   "source": [
    "# Transform TfIdf corpus into latent 2-D space using LSI\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 19:58:05,562 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "2020-04-01 19:58:05,563 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model.print_topics(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.06600783396090135), (1, -0.5200703306361859)],\n",
       " [(0, 0.1966759285914224), (1, -0.7609563167700061)],\n",
       " [(0, 0.08992639972446098), (1, -0.7241860626752515)],\n",
       " [(0, 0.0758584765217788), (1, -0.6320551586003432)],\n",
       " [(0, 0.10150299184979951), (1, -0.5737308483002963)],\n",
       " [(0, 0.7032108939378316), (1, 0.1611518021402547)],\n",
       " [(0, 0.8774787673119839), (1, 0.16758906864659018)],\n",
       " [(0, 0.9098624686818586), (1, 0.14086553628718618)],\n",
       " [(0, 0.6165825350569285), (1, -0.05392907566389632)]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lsi = lsi_model[corpus_tfidf]\n",
    "list(corpus_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.06600783396090135), (1, -0.5200703306361859)] Human machine interface for lab abc computer applications\n",
      "[(0, 0.1966759285914224), (1, -0.7609563167700061)] A survey of user opinion of computer system response time\n",
      "[(0, 0.08992639972446098), (1, -0.7241860626752515)] The EPS user interface management system\n",
      "[(0, 0.0758584765217788), (1, -0.6320551586003432)] System and human system engineering testing of EPS\n",
      "[(0, 0.10150299184979951), (1, -0.5737308483002963)] Relation of user perceived response time to error measurement\n",
      "[(0, 0.7032108939378316), (1, 0.1611518021402547)] The generation of random binary unordered trees\n",
      "[(0, 0.8774787673119839), (1, 0.16758906864659018)] The intersection graph of paths in trees\n",
      "[(0, 0.9098624686818586), (1, 0.14086553628718618)] Graph minors IV Widths of trees and well quasi ordering\n",
      "[(0, 0.6165825350569285), (1, -0.05392907566389632)] Graph minors A survey\n"
     ]
    }
   ],
   "source": [
    "for doc, as_text in zip(corpus_lsi, documents):\n",
    "    print(doc, as_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipped available transformation. That comes later in more depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Similarity Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 20:07:49,812 : INFO : using serial LSI version on this node\n",
      "2020-04-01 20:07:49,813 : INFO : updating model with new documents\n",
      "2020-04-01 20:07:49,813 : INFO : preparing a new chunk of documents\n",
      "2020-04-01 20:07:49,814 : INFO : using 100 extra samples and 2 power iterations\n",
      "2020-04-01 20:07:49,815 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2020-04-01 20:07:49,815 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2020-04-01 20:07:49,817 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2020-04-01 20:07:49,818 : INFO : computing the final decomposition\n",
      "2020-04-01 20:07:49,818 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
      "2020-04-01 20:07:49,819 : INFO : processed documents up to #9\n",
      "2020-04-01 20:07:49,820 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"time\" + 0.265*\"response\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2020-04-01 20:07:49,821 : INFO : topic #1(2.542): -0.623*\"graph\" + -0.490*\"trees\" + -0.451*\"minors\" + -0.274*\"survey\" + 0.167*\"system\" + 0.141*\"eps\" + 0.113*\"human\" + -0.107*\"time\" + -0.107*\"response\" + 0.072*\"interface\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.461821004532716), (1, 0.0700276652789995)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-01 20:08:57,613 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2020-04-01 20:08:57,623 : INFO : creating matrix with 9 documents and 2 features\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus]) # using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.998093  ,  0.93748635,  0.9984453 ,  0.9865886 ,  0.90755945,\n",
       "       -0.12416792, -0.10639259, -0.09879464,  0.05004176], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = index[vec_lsi]\n",
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.9984453),\n",
       " (0, 0.998093),\n",
       " (3, 0.9865886),\n",
       " (1, 0.93748635),\n",
       " (4, 0.90755945),\n",
       " (8, 0.050041765),\n",
       " (7, -0.09879464),\n",
       " (6, -0.10639259),\n",
       " (5, -0.12416792)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(enumerate(sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "in\n",
      "for\n",
      "that\n",
      "is\n",
      "on\n",
      "##\n",
      "The\n",
      "with\n",
      "said\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, word in enumerate(wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
       "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
       "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
       "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
       "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
       "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
       "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
       "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
       "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
       "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
       "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
       "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
       "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
       "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
       "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
       "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
       "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
       "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
       "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
       "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
       "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
       "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
       "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
       "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
       "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
       "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
       "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
       "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
       "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
       "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
       "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
       "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
       "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
       "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
       "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
       "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
       "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
       "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
       "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
       "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
       "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
       "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
       "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
       "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
       "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
       "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
       "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
       "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
       "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
       "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
       "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
       "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
       "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
       "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
       "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
       "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
       "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
       "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
       "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
       "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
       "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
       "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
       "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
       "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
       "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
       "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
       "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
       "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
       "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
       "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
       "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
       "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
       "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
       "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
       "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_king = wv['king']\n",
    "vec_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'cameroon' does not appear in this model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car'\t'minivan'\t0.69\n",
      "'car'\t'bicycle'\t0.54\n",
      "'car'\t'airplane'\t0.42\n",
      "'car'\t'cereal'\t0.14\n",
      "'car'\t'communism'\t0.06\n"
     ]
    }
   ],
   "source": [
    "pairs = [    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.8532191514968872), ('vehicle', 0.8175784349441528), ('pickup_truck', 0.7763689160346985), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565719485282898)]\n"
     ]
    }
   ],
   "source": [
    "print(wv.most_similar(positive=['car', 'minivan'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khachatur\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vec_king = model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hundreds\n",
      "of\n",
      "people\n",
      "have\n",
      "been\n",
      "forced\n",
      "to\n",
      "their\n",
      "homes\n",
      "in\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = [] # positions in vector space\n",
    "    labels = [] # keep track of words to label our data again later\n",
    "    for word in model.wv.vocab:\n",
    "        vectors.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "plot_with_matplotlib(x_vals, y_vals, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "# Set file names for train and test data\n",
    "test_data_dir = os.path.join(gensim.__path__[0], 'test', 'test_data')\n",
    "lee_train_file = os.path.join(test_data_dir, 'lee_background.cor')\n",
    "lee_test_file = os.path.join(test_data_dir, 'lee.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['argentina', 'political', 'and', 'economic', 'crisis', 'has', 'deepened', 'with', 'the', 'resignation', 'of', 'its', 'interim', 'president', 'who', 'took', 'office', 'just', 'week', 'ago', 'aldolfo', 'rodregiuez', 'saa', 'told', 'stunned', 'nation', 'that', 'he', 'could', 'not', 'rescue', 'argentina', 'because', 'key', 'fellow', 'peronists', 'would', 'not', 'support', 'his', 'default', 'on', 'massive', 'foreign', 'debt', 'repayment', 'or', 'his', 'plan', 'for', 'new', 'currency', 'it', 'was', 'only', 'week', 'ago', 'that', 'he', 'was', 'promising', 'million', 'new', 'jobs', 'to', 'end', 'four', 'years', 'of', 'recession', 'days', 'after', 'his', 'predecessor', 'resigned', 'following', 'series', 'of', 'failed', 'rescue', 'packages', 'after', 'announcing', 'that', 'the', 'senate', 'leader', 'ramon', 'puerta', 'would', 'assume', 'the', 'presidency', 'until', 'congress', 'appoints', 'new', 'caretaker', 'president', 'the', 'government', 'said', 'he', 'too', 'had', 'quit', 'and', 'another', 'senior', 'lawmaker', 'would', 'act', 'in', 'the', 'role', 'fresh', 'elections', 'are', 'not', 'scheduled', 'until', 'march', 'leaving', 'whoever', 'assumes', 'the', 'presidency', 'with', 'the', 'daunting', 'task', 'of', 'tackling', 'argentina', 'worst', 'crisis', 'in', 'years', 'but', 'this', 'time', 'isolated', 'by', 'international', 'lending', 'agencies'], tags=[3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_corpus[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3955"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03030773 -0.05393341 -0.13382047 -0.04441775  0.22714497  0.09742558\n",
      "  0.14442702  0.05052727  0.02953425 -0.0934954   0.08715063 -0.13288651\n",
      " -0.07523406  0.04768296  0.18364494  0.17692944  0.04612937 -0.0701591\n",
      "  0.11088675 -0.38414133 -0.11857495  0.07786534 -0.2572298  -0.03044146\n",
      " -0.06027896 -0.2198638  -0.03219892  0.20376648  0.00517268 -0.11205857\n",
      "  0.03470736  0.12120346 -0.0237193   0.00904524 -0.07099169  0.03126359\n",
      " -0.24987783  0.3558425  -0.10321619  0.08093851  0.05007556 -0.16718146\n",
      "  0.0469365   0.08548426 -0.13120362 -0.09851377 -0.25928763  0.05998456\n",
      "  0.05889411  0.0781127 ]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 292, 1: 8})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (299): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (299, 0.9405352473258972): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SECOND-MOST (146, 0.8215804100036621): «the australian and south african sides for the first cricket test starting at the adelaide oval today are not expected to be finalised until just before the start of play australian captain steve waugh and his south african counterpart shaun pollock will decide on their lineups after an inspection of the pitch shortly before the start of play the match holds special significance for waugh and his twin brother mark who play their th test together steve waugh is not placing too much relevance on the milestone don want to read too much into it guess and then get too carried away but later on when we retire and look back on it it will be significant it nice for the family mum and dad all the sacrifices they made you know with us growing up and also our brothers so you know it nice for the family he said»\n",
      "\n",
      "MEDIAN (288, 0.2838526964187622): «eight people are to appear in swiss court tomorrow charged with the manslaughter of tourists and three guides after the interlaken canyoning tragedy the first three defendants are managers of the now defunctoperator adventure world twenty one people including australians were killed when thunderstorm struck when they were canyoning down the saxeten river gorge near interlaken massive wall of water hit the group and swept them to their deaths it will be alleged the company adventure world allowed the trip to proceed with no safety provisions in place that they employed inexperienced staff and guides who had lack of knowledge about the violent weather changes which can occur in the mountains if convicted they face one year jail sentence»\n",
      "\n",
      "LEAST (223, -0.11083419620990753): «indonesian troop re enforcements have started arriving in central sulawesi as the government attempts to end days of deadly clashes between christians and muslims violence in the last week has claimed at least eight lives and left thousands of people homeless more than police and soldiers are being sent in to disarm rival groups and restore calm there have been no new reports of violence but residents in the christian town of ten tena say they fear further attacks by muslim militiamen taking up positions in the hills around the town in region where fighting between muslims and christians has claimed hundreds of lives in the last two years many blame the latest upsurge in violence on the arrival of members of the laskar jihad muslim militia from training camps in java and from the neighbouring maluka islands»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (34): «prince william has told friends his mother was right all along to suspect her former protection officer of spying on her and he doesn want any detective intruding on his own privacy william and prince harry are so devastated by the treachery of ken wharfe whom they looked on as surrogate father they are now refusing to talk to their own detectives»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (45, 0.7441575527191162): «sir nigel hawthorne the british actor best known for his role as the scheming civil servant in the bbc hit yes minister died wednesday from heart attack aged his agent said hawthorne had been battling cancer for the past months and had just come out of hospital where he had been having chemotherapy treatment said ken mcreddie he said the cancer treatment had been going well and the heart attack was unexpected hawthorne died peacefully at home with his partner and friend mcreddie added he was brilliant actor and wonderful friend feel very sad and extremely cut up he said playing the smug civil servant sir humphrey appleby who always knew better than his master hawthorne performances in yes minister won him host of awards and the glowing approval of then prime minister margaret thatcher the role led to sequel yes prime minister as well as range of more substantial role on stage and screen including the lead role in the film the madness of king george for which he was nominated for an oscar»\n",
      "\n",
      "MEDIAN (95, 0.46624213457107544): «legal abortion in tasmania is one step closer with the lower house of parliament voting to change the state abortion laws after marathon hour debate the house of assembly this morning passed by votes to eight private member bill which would allow medically sanctioned abortions debate on the bill began at am aedt yesterday and at am today speaker michael polley declared result just before pm the deputy premier paul lennon police minister david llewellyn and labor backbencher steven kons abstained from voting on the bill second reading then came seven hours of debate on proposed amendments calling for further expert opinion post procedure counselling cooling off periods and calls to stop the bill being retrospective but apart from an amendment to ensure specialist assessment and written consent for the procedure the bill passed unchanged the legislative council will begin debate on the bill at am today»\n",
      "\n",
      "LEAST (8, 0.1184057667851448): «there has been welcome relief for firefighters in new south wales overnight with milder weather allowing them to strengthen containment lines around the most severe fires but fire authorities are not getting overly optimistic as dry and hot weather is forecast to continue the weather bureau is forecasting temperatures in the high and westerly winds until at least friday which means fire authorities are reluctant to get too excited about last night favourable conditions marks sullivan from the rural fire service says fire fighters are remaining on guard lot of fires that have been burning in the areas around sydney and the north coast and further south have been burning within areas that are known and are contained he said however that not to say that these fires won pose threat given the weather conditions that are coming up over the next few days despite the caution the rural fire service says most of the state fires that threaten property are burning within containment lines greater sydney is ringed by fires to the north west and south two of those flared overnight one at appin in the southern highlands was quickly brought under control another flare up at spencer north of the city is not contained on its north western flank but is not threatening property in the lower blue mountains west of sydney firefighters have spent the night setting up kilometre containment line to protect communities along the great western highway from glenbrook to bulaburra two fires burning near cessnock west of newcastle are still within containment lines in the state north aircraft will this morning check if lightning from large electrical storm overnight has sparked any new fires above grafton aircraft have also been used in the shoalhaven area in the state south to drop incendiary devices that start fire control lines in inaccessible areas the rural fire service commissioner phil koperberg says if fire activity increases hundreds of new year eve fireworks celebrations in new south wales will be cancelled»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Similarity Queries with Annoy and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS = False\n",
    "if LOGS:\n",
    "    import logging\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Khachatur/gensim-data\\\\text8\\\\text8.gz'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "text8_path = api.load('text8', return_path=True)\n",
    "text8_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=71290, size=100, alpha=0.05)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "# Using params from Word2Vec_FastText_Comparison\n",
    "params = {\n",
    "    'alpha': 0.05,\n",
    "    'size': 100,\n",
    "    'window': 5,\n",
    "    'iter': 5,\n",
    "    'min_count': 5,\n",
    "    'sample': 1e-4,\n",
    "    'sg': 1,\n",
    "    'hs': 0,\n",
    "    'negative': 5\n",
    "}\n",
    "model = Word2Vec(Text8Corpus(text8_path), **params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Annoy has not been installed, if you wish to use the annoy indexer, please run `pip install annoy`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\similarities\\index.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mannoy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnnoyIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'annoy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-13e1972fa8eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnnoyIndexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# 100 trees are being used in this example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mannoy_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnnoyIndexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Derive the vector for the word \"science\" in our model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"science\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\similarities\\index.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     raise ImportError(\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;34m\"Annoy has not been installed, if you wish to use the annoy indexer, please run `pip install annoy`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Annoy has not been installed, if you wish to use the annoy indexer, please run `pip install annoy`"
     ]
    }
   ],
   "source": [
    "from gensim.similarities.index import AnnoyIndexer\n",
    "# 100 trees are being used in this example\n",
    "annoy_index = AnnoyIndexer(model, 100)\n",
    "# Derive the vector for the word \"science\" in our model\n",
    "vector = model.wv[\"science\"]\n",
    "# The instance of AnnoyIndexer we just created is passed\n",
    "approximate_neighbors = model.wv.most_similar([vector], topn=11, indexer=annoy_index)\n",
    "# Neatly print the approximate_neighbors and their corresponding cosine similarity values\n",
    "print(\"Approximate Neighbors\")\n",
    "for neighbor in approximate_neighbors:\n",
    "    print(neighbor)\n",
    "\n",
    "normal_neighbors = model.wv.most_similar([vector], topn=11)\n",
    "print(\"\\nNormal (not Annoy-indexed) Neighbors\")\n",
    "for neighbor in normal_neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip for now since I don't feel like restarting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os.path\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import smart_open\n",
    "\n",
    "def extract_documents(url='https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'):\n",
    "    fname = url.split('/')[-1]\n",
    "\n",
    "    # Download the file to local storage first.\n",
    "    # We can't read it on the fly because of\n",
    "    # https://github.com/RaRe-Technologies/smart_open/issues/331\n",
    "    if not os.path.isfile(fname):\n",
    "        with smart_open.open(url, \"rb\") as fin:\n",
    "            with smart_open.open(fname, 'wb') as fout:\n",
    "                while True:\n",
    "                    buf = fin.read(io.DEFAULT_BUFFER_SIZE)\n",
    "                    if not buf:\n",
    "                        break\n",
    "                    fout.write(buf)\n",
    "\n",
    "    with tarfile.open(fname, mode='r:gz') as tar:\n",
    "        # Ignore directory entries, as well as files like README, etc.\n",
    "        files = [\n",
    "            m for m in tar.getmembers()\n",
    "            if m.isfile() and re.search(r'nipstxt/nips\\d+/\\d+\\.txt', m.name)\n",
    "        ]\n",
    "        for member in sorted(files, key=lambda x: x.name):\n",
    "            member_bytes = tar.extractfile(member).read()\n",
    "            yield member_bytes.decode('utf-8', errors='replace')\n",
    "\n",
    "docs = list(extract_documents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "1 \n",
      "CONNECTIVITY VERSUS ENTROPY \n",
      "Yaser S. Abu-Mostafa \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91125 \n",
      "ABSTRACT \n",
      "How does the connectivity of a neural network (number of synapses per \n",
      "neuron) relate to the complexity of the problems it can handle (measured by \n",
      "the entropy)? Switching theory would suggest no relation at all, since all Boolean \n",
      "functions can be implemented using a circuit with very low connectivity (e.g., \n",
      "using two-input NAND gates). However, for a network that learns a pr\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(docs[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['connectivity', 'versus', 'entropy', 'yaser', 'abu', 'mostafa', 'california', 'institute', 'of', 'technology', 'pasadena', 'ca', 'abstract', 'how', 'doe', 'the', 'connectivity', 'of', 'neural', 'network', 'number', 'of', 'synapsis', 'per', 'neuron', 'relate', 'to', 'the', 'complexity', 'of', 'the', 'problem', 'it', 'can', 'handle', 'measured', 'by', 'the', 'entropy', 'switching', 'theory', 'would', 'suggest', 'no', 'relation', 'at', 'all', 'since', 'all', 'boolean', 'function', 'can', 'be', 'implemented', 'using', 'circuit', 'with', 'very', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'for', 'network', 'that', 'learns', 'problem', 'from', 'example', 'using', 'local', 'learning', 'rule', 'we', 'prove', 'that', 'the', 'entropy', 'of', 'the', 'problem', 'becomes', 'lower', 'bound', 'for', 'the', 'connectivity', 'of', 'the', 'network', 'introduction', 'the', 'most', 'distinguishing', 'feature', 'of', 'neural', 'network', 'is', 'their', 'ability', 'to', 'spon', 'taneously', 'learn', 'the', 'desired', 'function', 'from', 'training', 'sample', 'their', 'ability', 'to', 'program', 'themselves', 'clearly', 'given', 'neural', 'network', 'cannot', 'just', 'learn', 'any', 'function', 'there', 'must', 'be', 'some', 'restriction', 'on', 'which', 'network', 'can', 'learn', 'which', 'function', 'one', 'obvious', 'restriction', 'which', 'is', 'independent', 'of', 'the', 'learning', 'aspect', 'is', 'that', 'the', 'network', 'must', 'be', 'big', 'enough', 'to', 'accommodate', 'the', 'circuit', 'complex', 'ity', 'of', 'the', 'function', 'it', 'will', 'eventually', 'simulate', 'are', 'there', 'restriction', 'that', 'arise', 'merely', 'from', 'the', 'fact', 'that', 'the', 'network', 'is', 'expected', 'to', 'learn', 'the', 'function', 'rather', 'than', 'being', 'purposely', 'designed', 'for', 'the', 'function', 'this', 'paper', 'report', 'restriction', 'of', 'this', 'kind', 'the', 'result', 'imposes', 'lower', 'bound', 'on', 'the', 'connectivity', 'of', 'the', 'network', 'num', 'ber', 'of', 'synapsis', 'per', 'neuron', 'this', 'lower', 'bound', 'can', 'only', 'be', 'consequence', 'of', 'the', 'learning', 'aspect', 'since', 'switching', 'theory', 'provides', 'purposely', 'designed', 'circuit', 'of', 'low', 'connectivity', 'using', 'only', 'two', 'input', 'nand', 'gate', 'capable', 'of', 'imple', 'menting', 'any', 'boolean', 'function', 'it', 'also', 'follows', 'that', 'the', 'learning', 'mechanism', 'must', 'be', 'restricted', 'for', 'this', 'lower', 'bound', 'to', 'hold', 'powerful', 'mechanism', 'can', 'be', 'american', 'institute', 'of', 'physic', 'designed', 'that', 'will', 'find', 'one', 'of', 'the', 'low', 'connectivity', 'circuit', 'perhaps', 'by', 'exhaus', 'tive', 'search', 'and', 'hence', 'the', 'lower', 'bound', 'on', 'connectivity', 'cannot', 'hold', 'in', 'general', 'indeed', 'we', 'restrict', 'the', 'learning', 'mechanism', 'to', 'be', 'local', 'when', 'training', 'sample', 'is', 'loaded', 'into', 'the', 'network', 'each', 'neuron', 'ha', 'access', 'only', 'to', 'those', 'bit', 'carried', 'by', 'itself', 'and', 'the', 'neuron', 'it', 'is', 'directly', 'connected', 'to', 'this', 'is', 'strong', 'assumption', 'that', 'excludes', 'sophisticated', 'learning', 'mechanism', 'used', 'in', 'neural', 'network', 'model', 'but', 'may', 'be', 'more', 'plausible', 'from', 'biological', 'point', 'of', 'view', 'the', 'lower', 'bound', 'on', 'the', 'connectivity', 'of', 'the', 'network', 'is', 'given', 'in', 'term', 'of', 'the', 'entropy', 'of', 'the', 'environment', 'that', 'provides', 'the', 'training', 'sample', 'entropy', 'is', 'quantitative', 'measure', 'of', 'the', 'disorder', 'or', 'randomness', 'in', 'an', 'environment', 'or', 'equiv', 'alently', 'the', 'amount', 'of', 'information', 'needed', 'to', 'specify', 'the', 'environment', 'there', 'are', 'many', 'different', 'way', 'to', 'define', 'entropy', 'and', 'many', 'technical', 'variation', 'of', 'this', 'concept', 'in', 'the', 'next', 'section', 'we', 'shall', 'introduce', 'the', 'formal', 'definition', 'and', 'result', 'but', 'we', 'start', 'here', 'with', 'an', 'informal', 'exposition', 'of', 'the', 'idea', 'involved', 'the', 'environment', 'in', 'our', 'model', 'produce', 'pattern', 'represented', 'by', 'bit', 'xn', 'pixel', 'in', 'the', 'picture', 'of', 'visual', 'scene', 'if', 'you', 'will', 'only', 'different', 'pattern', 'can', 'be', 'generated', 'by', 'given', 'environment', 'where', 'the', 'entropy', 'is', 'essentially', 'log', 'no', 'knowledge', 'is', 'assumed', 'about', 'which', 'pattern', 'the', 'en', 'vironment', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(docs[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-04 03:00:46,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-04-04 03:00:50,828 : INFO : built Dictionary(76323 unique tokens: ['0a', '2h', '2h2', '2he', '2n']...) from 1740 documents (total 4629808 corpus positions)\n",
      "2020-04-04 03:00:51,058 : INFO : discarding 69706 tokens: [('0a', 19), ('2h', 16), ('2h2', 1), ('2he', 3), ('__c', 2), ('_k', 6), ('a', 1740), ('about', 1058), ('abstract', 1740), ('after', 1087)]...\n",
      "2020-04-04 03:00:51,059 : INFO : keeping 6617 tokens which were in no less than 20 and no more than 870 (=50.0%) documents\n",
      "2020-04-04 03:00:51,098 : INFO : resulting dictionary: Dictionary(6617 unique tokens: ['2n', '_c', 'a2', 'ability', 'abu']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 6617\n",
      "Number of documents: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-04 03:00:53,671 : INFO : using autotuned alpha, starting with [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "2020-04-04 03:00:53,674 : INFO : using serial LDA version on this node\n",
      "2020-04-04 03:00:53,688 : INFO : running online (multi-pass) LDA training, 10 topics, 20 passes over the supplied corpus of 1740 documents, updating model once every 1740 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2020-04-04 03:00:53,689 : INFO : PROGRESS: pass 0, at document #1740/1740\n",
      "2020-04-04 03:01:13,576 : INFO : optimized alpha [0.074996874, 0.08459729, 0.08756085, 0.066903315, 0.06125561, 0.069220856, 0.06397121, 0.04192957, 0.078885034, 0.09185236]\n",
      "2020-04-04 03:01:13,586 : INFO : topic #7 (0.042): 0.007*\"hidden\" + 0.005*\"gradient\" + 0.004*\"rule\" + 0.004*\"speech\" + 0.004*\"classifier\" + 0.004*\"matrix\" + 0.004*\"recognition\" + 0.003*\"sequence\" + 0.003*\"source\" + 0.003*\"class\"\n",
      "2020-04-04 03:01:13,589 : INFO : topic #4 (0.061): 0.010*\"neuron\" + 0.005*\"cell\" + 0.004*\"synaptic\" + 0.004*\"tree\" + 0.004*\"node\" + 0.003*\"class\" + 0.003*\"dynamic\" + 0.003*\"response\" + 0.003*\"layer\" + 0.003*\"stimulus\"\n",
      "2020-04-04 03:01:13,590 : INFO : topic #1 (0.085): 0.007*\"image\" + 0.005*\"hidden\" + 0.004*\"neuron\" + 0.004*\"field\" + 0.004*\"layer\" + 0.003*\"class\" + 0.003*\"sample\" + 0.003*\"recognition\" + 0.003*\"map\" + 0.003*\"cell\"\n",
      "2020-04-04 03:01:13,591 : INFO : topic #2 (0.088): 0.008*\"neuron\" + 0.005*\"layer\" + 0.004*\"control\" + 0.004*\"cell\" + 0.004*\"image\" + 0.003*\"class\" + 0.003*\"object\" + 0.003*\"classifier\" + 0.003*\"classification\" + 0.003*\"hidden\"\n",
      "2020-04-04 03:01:13,592 : INFO : topic #9 (0.092): 0.006*\"image\" + 0.005*\"node\" + 0.005*\"object\" + 0.004*\"recognition\" + 0.003*\"cell\" + 0.003*\"layer\" + 0.003*\"neuron\" + 0.003*\"signal\" + 0.003*\"distance\" + 0.003*\"circuit\"\n",
      "2020-04-04 03:01:13,595 : INFO : topic diff=1.218716, rho=1.000000\n",
      "2020-04-04 03:01:13,603 : INFO : PROGRESS: pass 1, at document #1740/1740\n",
      "2020-04-04 03:01:26,487 : INFO : optimized alpha [0.06181817, 0.06855679, 0.06839618, 0.05530875, 0.05254131, 0.060496654, 0.05590432, 0.038310137, 0.065804295, 0.07350954]\n",
      "2020-04-04 03:01:26,494 : INFO : topic #7 (0.038): 0.009*\"speech\" + 0.009*\"hidden\" + 0.008*\"recognition\" + 0.006*\"classifier\" + 0.005*\"hmm\" + 0.005*\"speaker\" + 0.005*\"gradient\" + 0.005*\"class\" + 0.004*\"sequence\" + 0.004*\"matrix\"\n",
      "2020-04-04 03:01:26,497 : INFO : topic #4 (0.053): 0.015*\"neuron\" + 0.008*\"cell\" + 0.007*\"spike\" + 0.007*\"synaptic\" + 0.005*\"tree\" + 0.004*\"stimulus\" + 0.004*\"response\" + 0.004*\"node\" + 0.003*\"frequency\" + 0.003*\"firing\"\n",
      "2020-04-04 03:01:26,497 : INFO : topic #2 (0.068): 0.009*\"neuron\" + 0.006*\"control\" + 0.006*\"layer\" + 0.005*\"cell\" + 0.004*\"object\" + 0.004*\"image\" + 0.004*\"connection\" + 0.003*\"classifier\" + 0.003*\"class\" + 0.003*\"visual\"\n",
      "2020-04-04 03:01:26,499 : INFO : topic #1 (0.069): 0.008*\"image\" + 0.005*\"hidden\" + 0.004*\"field\" + 0.004*\"layer\" + 0.004*\"class\" + 0.003*\"sample\" + 0.003*\"neuron\" + 0.003*\"bound\" + 0.003*\"policy\" + 0.003*\"optimal\"\n",
      "2020-04-04 03:01:26,500 : INFO : topic #9 (0.074): 0.009*\"image\" + 0.006*\"object\" + 0.005*\"node\" + 0.004*\"recognition\" + 0.004*\"circuit\" + 0.004*\"distance\" + 0.003*\"chip\" + 0.003*\"layer\" + 0.003*\"cell\" + 0.003*\"signal\"\n",
      "2020-04-04 03:01:26,501 : INFO : topic diff=0.261926, rho=0.577350\n",
      "2020-04-04 03:01:26,509 : INFO : PROGRESS: pass 2, at document #1740/1740\n",
      "2020-04-04 03:01:36,393 : INFO : optimized alpha [0.053771965, 0.060286723, 0.05785556, 0.049609374, 0.04817763, 0.056392804, 0.051345963, 0.036844883, 0.059142593, 0.06459683]\n",
      "2020-04-04 03:01:36,402 : INFO : topic #7 (0.037): 0.012*\"speech\" + 0.010*\"recognition\" + 0.009*\"hidden\" + 0.008*\"classifier\" + 0.007*\"word\" + 0.006*\"hmm\" + 0.006*\"class\" + 0.005*\"speaker\" + 0.005*\"sequence\" + 0.005*\"gradient\"\n",
      "2020-04-04 03:01:36,403 : INFO : topic #4 (0.048): 0.019*\"neuron\" + 0.011*\"cell\" + 0.009*\"spike\" + 0.008*\"synaptic\" + 0.005*\"stimulus\" + 0.005*\"response\" + 0.005*\"firing\" + 0.004*\"frequency\" + 0.004*\"tree\" + 0.004*\"activity\"\n",
      "2020-04-04 03:01:36,404 : INFO : topic #8 (0.059): 0.007*\"noise\" + 0.006*\"gaussian\" + 0.004*\"matrix\" + 0.004*\"hidden\" + 0.004*\"layer\" + 0.003*\"bayesian\" + 0.003*\"prediction\" + 0.003*\"regression\" + 0.003*\"basis\" + 0.003*\"prior\"\n",
      "2020-04-04 03:01:36,404 : INFO : topic #1 (0.060): 0.007*\"image\" + 0.005*\"hidden\" + 0.004*\"policy\" + 0.004*\"optimal\" + 0.004*\"class\" + 0.004*\"bound\" + 0.004*\"field\" + 0.004*\"let\" + 0.004*\"action\" + 0.004*\"layer\"\n",
      "2020-04-04 03:01:36,405 : INFO : topic #9 (0.065): 0.013*\"image\" + 0.007*\"object\" + 0.005*\"circuit\" + 0.005*\"chip\" + 0.005*\"node\" + 0.005*\"recognition\" + 0.004*\"distance\" + 0.004*\"analog\" + 0.003*\"layer\" + 0.003*\"voltage\"\n",
      "2020-04-04 03:01:36,408 : INFO : topic diff=0.229410, rho=0.500000\n",
      "2020-04-04 03:01:36,423 : INFO : PROGRESS: pass 3, at document #1740/1740\n",
      "2020-04-04 03:01:44,932 : INFO : optimized alpha [0.048468936, 0.055245616, 0.051836986, 0.04675383, 0.04551365, 0.05380342, 0.048376616, 0.03608928, 0.055240996, 0.059345808]\n",
      "2020-04-04 03:01:44,941 : INFO : topic #7 (0.036): 0.013*\"speech\" + 0.012*\"recognition\" + 0.010*\"hidden\" + 0.009*\"classifier\" + 0.009*\"word\" + 0.006*\"class\" + 0.006*\"hmm\" + 0.006*\"sequence\" + 0.006*\"speaker\" + 0.005*\"layer\"\n",
      "2020-04-04 03:01:44,942 : INFO : topic #4 (0.046): 0.022*\"neuron\" + 0.013*\"cell\" + 0.009*\"spike\" + 0.008*\"synaptic\" + 0.007*\"response\" + 0.006*\"stimulus\" + 0.006*\"firing\" + 0.005*\"frequency\" + 0.005*\"activity\" + 0.004*\"potential\"\n",
      "2020-04-04 03:01:44,944 : INFO : topic #1 (0.055): 0.006*\"policy\" + 0.005*\"image\" + 0.005*\"hidden\" + 0.005*\"optimal\" + 0.005*\"action\" + 0.004*\"class\" + 0.004*\"bound\" + 0.004*\"let\" + 0.004*\"solution\" + 0.003*\"node\"\n",
      "2020-04-04 03:01:44,948 : INFO : topic #8 (0.055): 0.007*\"noise\" + 0.007*\"gaussian\" + 0.005*\"matrix\" + 0.004*\"hidden\" + 0.004*\"layer\" + 0.004*\"variance\" + 0.004*\"bayesian\" + 0.004*\"basis\" + 0.004*\"regression\" + 0.004*\"kernel\"\n",
      "2020-04-04 03:01:44,951 : INFO : topic #9 (0.059): 0.015*\"image\" + 0.008*\"object\" + 0.006*\"chip\" + 0.006*\"circuit\" + 0.005*\"recognition\" + 0.004*\"node\" + 0.004*\"distance\" + 0.004*\"analog\" + 0.004*\"face\" + 0.003*\"layer\"\n",
      "2020-04-04 03:01:44,953 : INFO : topic diff=0.205960, rho=0.447214\n",
      "2020-04-04 03:01:44,962 : INFO : PROGRESS: pass 4, at document #1740/1740\n",
      "2020-04-04 03:01:53,457 : INFO : optimized alpha [0.04491942, 0.05173589, 0.04805323, 0.044992596, 0.043574095, 0.052108765, 0.04656888, 0.03566036, 0.052795865, 0.056131862]\n",
      "2020-04-04 03:01:53,467 : INFO : topic #7 (0.036): 0.014*\"speech\" + 0.013*\"recognition\" + 0.011*\"word\" + 0.010*\"classifier\" + 0.010*\"hidden\" + 0.007*\"class\" + 0.006*\"sequence\" + 0.006*\"hmm\" + 0.006*\"speaker\" + 0.006*\"layer\"\n",
      "2020-04-04 03:01:53,467 : INFO : topic #4 (0.044): 0.023*\"neuron\" + 0.015*\"cell\" + 0.010*\"spike\" + 0.008*\"synaptic\" + 0.007*\"response\" + 0.007*\"stimulus\" + 0.007*\"firing\" + 0.005*\"activity\" + 0.005*\"frequency\" + 0.004*\"potential\"\n",
      "2020-04-04 03:01:53,471 : INFO : topic #5 (0.052): 0.006*\"mixture\" + 0.006*\"sample\" + 0.005*\"class\" + 0.005*\"estimate\" + 0.005*\"density\" + 0.004*\"classification\" + 0.004*\"prediction\" + 0.004*\"tree\" + 0.004*\"bound\" + 0.004*\"em\"\n",
      "2020-04-04 03:01:53,472 : INFO : topic #8 (0.053): 0.008*\"noise\" + 0.007*\"gaussian\" + 0.005*\"matrix\" + 0.005*\"hidden\" + 0.004*\"variance\" + 0.004*\"component\" + 0.004*\"basis\" + 0.004*\"layer\" + 0.004*\"kernel\" + 0.004*\"prior\"\n",
      "2020-04-04 03:01:53,473 : INFO : topic #9 (0.056): 0.018*\"image\" + 0.008*\"object\" + 0.006*\"chip\" + 0.006*\"circuit\" + 0.005*\"recognition\" + 0.005*\"analog\" + 0.005*\"distance\" + 0.004*\"node\" + 0.004*\"face\" + 0.004*\"pixel\"\n",
      "2020-04-04 03:01:53,473 : INFO : topic diff=0.190263, rho=0.408248\n",
      "2020-04-04 03:01:53,484 : INFO : PROGRESS: pass 5, at document #1740/1740\n",
      "2020-04-04 03:02:02,285 : INFO : optimized alpha [0.04232133, 0.049155794, 0.045391552, 0.043926504, 0.042237893, 0.05093983, 0.04546526, 0.035398178, 0.051467642, 0.05414131]\n",
      "2020-04-04 03:02:02,294 : INFO : topic #7 (0.035): 0.015*\"speech\" + 0.013*\"recognition\" + 0.012*\"word\" + 0.010*\"classifier\" + 0.010*\"hidden\" + 0.007*\"class\" + 0.006*\"sequence\" + 0.006*\"context\" + 0.006*\"hmm\" + 0.006*\"layer\"\n",
      "2020-04-04 03:02:02,294 : INFO : topic #4 (0.042): 0.024*\"neuron\" + 0.016*\"cell\" + 0.010*\"spike\" + 0.009*\"synaptic\" + 0.008*\"response\" + 0.007*\"stimulus\" + 0.007*\"firing\" + 0.006*\"activity\" + 0.005*\"frequency\" + 0.005*\"potential\"\n",
      "2020-04-04 03:02:02,298 : INFO : topic #5 (0.051): 0.006*\"mixture\" + 0.006*\"class\" + 0.006*\"sample\" + 0.005*\"tree\" + 0.005*\"estimate\" + 0.005*\"density\" + 0.005*\"classification\" + 0.004*\"prediction\" + 0.004*\"em\" + 0.004*\"bound\"\n",
      "2020-04-04 03:02:02,300 : INFO : topic #8 (0.051): 0.008*\"noise\" + 0.008*\"gaussian\" + 0.005*\"matrix\" + 0.005*\"hidden\" + 0.004*\"variance\" + 0.004*\"component\" + 0.004*\"basis\" + 0.004*\"kernel\" + 0.004*\"prior\" + 0.004*\"approximation\"\n",
      "2020-04-04 03:02:02,301 : INFO : topic #9 (0.054): 0.020*\"image\" + 0.008*\"object\" + 0.007*\"chip\" + 0.006*\"circuit\" + 0.005*\"recognition\" + 0.005*\"analog\" + 0.005*\"distance\" + 0.004*\"pixel\" + 0.004*\"face\" + 0.004*\"node\"\n",
      "2020-04-04 03:02:02,302 : INFO : topic diff=0.179167, rho=0.377964\n",
      "2020-04-04 03:02:02,309 : INFO : PROGRESS: pass 6, at document #1740/1740\n",
      "2020-04-04 03:02:10,653 : INFO : optimized alpha [0.040442254, 0.04737853, 0.04354218, 0.04328608, 0.041275233, 0.050247148, 0.045002982, 0.03525054, 0.050914064, 0.052787937]\n",
      "2020-04-04 03:02:10,664 : INFO : topic #7 (0.035): 0.015*\"speech\" + 0.014*\"recognition\" + 0.013*\"word\" + 0.010*\"classifier\" + 0.010*\"hidden\" + 0.007*\"class\" + 0.007*\"sequence\" + 0.006*\"context\" + 0.006*\"layer\" + 0.006*\"hmm\"\n",
      "2020-04-04 03:02:10,668 : INFO : topic #0 (0.040): 0.012*\"cell\" + 0.010*\"signal\" + 0.006*\"noise\" + 0.006*\"response\" + 0.006*\"direction\" + 0.006*\"correlation\" + 0.005*\"activity\" + 0.005*\"layer\" + 0.005*\"visual\" + 0.004*\"frequency\"\n",
      "2020-04-04 03:02:10,669 : INFO : topic #5 (0.050): 0.006*\"class\" + 0.006*\"mixture\" + 0.006*\"sample\" + 0.006*\"tree\" + 0.005*\"estimate\" + 0.005*\"density\" + 0.005*\"classification\" + 0.004*\"em\" + 0.004*\"prediction\" + 0.004*\"bound\"\n",
      "2020-04-04 03:02:10,670 : INFO : topic #8 (0.051): 0.008*\"noise\" + 0.008*\"gaussian\" + 0.005*\"matrix\" + 0.005*\"hidden\" + 0.004*\"component\" + 0.004*\"variance\" + 0.004*\"basis\" + 0.004*\"kernel\" + 0.004*\"approximation\" + 0.004*\"prior\"\n",
      "2020-04-04 03:02:10,672 : INFO : topic #9 (0.053): 0.021*\"image\" + 0.009*\"object\" + 0.007*\"chip\" + 0.007*\"circuit\" + 0.005*\"recognition\" + 0.005*\"analog\" + 0.005*\"distance\" + 0.004*\"pixel\" + 0.004*\"face\" + 0.004*\"visual\"\n",
      "2020-04-04 03:02:10,672 : INFO : topic diff=0.170628, rho=0.353553\n",
      "2020-04-04 03:02:10,686 : INFO : PROGRESS: pass 7, at document #1740/1740\n",
      "2020-04-04 03:02:18,596 : INFO : optimized alpha [0.039047096, 0.046022147, 0.0422371, 0.04301066, 0.0406421, 0.049738474, 0.04487479, 0.035248015, 0.050739754, 0.051811006]\n",
      "2020-04-04 03:02:18,606 : INFO : topic #7 (0.035): 0.016*\"speech\" + 0.015*\"recognition\" + 0.013*\"word\" + 0.011*\"classifier\" + 0.010*\"hidden\" + 0.007*\"class\" + 0.007*\"sequence\" + 0.006*\"context\" + 0.006*\"layer\" + 0.006*\"hmm\"\n",
      "2020-04-04 03:02:18,610 : INFO : topic #0 (0.039): 0.012*\"cell\" + 0.011*\"signal\" + 0.006*\"response\" + 0.006*\"noise\" + 0.006*\"direction\" + 0.006*\"correlation\" + 0.005*\"activity\" + 0.005*\"visual\" + 0.005*\"frequency\" + 0.005*\"layer\"\n",
      "2020-04-04 03:02:18,612 : INFO : topic #5 (0.050): 0.007*\"class\" + 0.006*\"mixture\" + 0.006*\"tree\" + 0.006*\"sample\" + 0.005*\"estimate\" + 0.005*\"classification\" + 0.005*\"density\" + 0.004*\"em\" + 0.004*\"prediction\" + 0.004*\"likelihood\"\n",
      "2020-04-04 03:02:18,612 : INFO : topic #8 (0.051): 0.008*\"noise\" + 0.008*\"gaussian\" + 0.006*\"matrix\" + 0.005*\"hidden\" + 0.005*\"component\" + 0.005*\"variance\" + 0.004*\"basis\" + 0.004*\"approximation\" + 0.004*\"kernel\" + 0.004*\"prior\"\n",
      "2020-04-04 03:02:18,615 : INFO : topic #9 (0.052): 0.022*\"image\" + 0.009*\"object\" + 0.007*\"chip\" + 0.007*\"circuit\" + 0.005*\"analog\" + 0.005*\"recognition\" + 0.005*\"distance\" + 0.005*\"pixel\" + 0.004*\"face\" + 0.004*\"visual\"\n",
      "2020-04-04 03:02:18,615 : INFO : topic diff=0.163362, rho=0.333333\n",
      "2020-04-04 03:02:18,626 : INFO : PROGRESS: pass 8, at document #1740/1740\n",
      "2020-04-04 03:02:26,236 : INFO : optimized alpha [0.038130507, 0.045007765, 0.041352354, 0.042886008, 0.040161565, 0.049416773, 0.04494917, 0.035346426, 0.05080649, 0.05116728]\n",
      "2020-04-04 03:02:26,251 : INFO : topic #7 (0.035): 0.016*\"speech\" + 0.015*\"recognition\" + 0.014*\"word\" + 0.011*\"classifier\" + 0.009*\"hidden\" + 0.008*\"class\" + 0.007*\"sequence\" + 0.007*\"context\" + 0.006*\"layer\" + 0.006*\"hmm\"\n",
      "2020-04-04 03:02:26,251 : INFO : topic #0 (0.038): 0.012*\"cell\" + 0.012*\"signal\" + 0.007*\"response\" + 0.007*\"direction\" + 0.007*\"noise\" + 0.006*\"correlation\" + 0.006*\"frequency\" + 0.006*\"visual\" + 0.005*\"activity\" + 0.005*\"stimulus\"\n",
      "2020-04-04 03:02:26,251 : INFO : topic #5 (0.049): 0.007*\"class\" + 0.006*\"mixture\" + 0.006*\"tree\" + 0.006*\"sample\" + 0.005*\"estimate\" + 0.005*\"classification\" + 0.005*\"density\" + 0.005*\"em\" + 0.004*\"prediction\" + 0.004*\"likelihood\"\n",
      "2020-04-04 03:02:26,255 : INFO : topic #8 (0.051): 0.008*\"gaussian\" + 0.008*\"noise\" + 0.006*\"matrix\" + 0.006*\"hidden\" + 0.005*\"component\" + 0.005*\"variance\" + 0.004*\"basis\" + 0.004*\"approximation\" + 0.004*\"kernel\" + 0.004*\"prior\"\n",
      "2020-04-04 03:02:26,256 : INFO : topic #9 (0.051): 0.023*\"image\" + 0.009*\"object\" + 0.007*\"chip\" + 0.007*\"circuit\" + 0.005*\"analog\" + 0.005*\"recognition\" + 0.005*\"distance\" + 0.005*\"pixel\" + 0.005*\"face\" + 0.004*\"visual\"\n",
      "2020-04-04 03:02:26,257 : INFO : topic diff=0.156573, rho=0.316228\n",
      "2020-04-04 03:02:26,265 : INFO : PROGRESS: pass 9, at document #1740/1740\n",
      "2020-04-04 03:02:33,416 : INFO : optimized alpha [0.037460588, 0.044230904, 0.040748037, 0.04287645, 0.039714947, 0.049221117, 0.045204237, 0.03555026, 0.05106599, 0.05073482]\n",
      "2020-04-04 03:02:33,428 : INFO : topic #7 (0.036): 0.017*\"speech\" + 0.016*\"recognition\" + 0.014*\"word\" + 0.011*\"classifier\" + 0.009*\"hidden\" + 0.008*\"class\" + 0.007*\"sequence\" + 0.007*\"context\" + 0.007*\"layer\" + 0.006*\"speaker\"\n",
      "2020-04-04 03:02:33,429 : INFO : topic #0 (0.037): 0.012*\"signal\" + 0.012*\"cell\" + 0.007*\"response\" + 0.007*\"direction\" + 0.007*\"noise\" + 0.006*\"frequency\" + 0.006*\"visual\" + 0.006*\"correlation\" + 0.006*\"stimulus\" + 0.005*\"activity\"\n",
      "2020-04-04 03:02:33,431 : INFO : topic #5 (0.049): 0.007*\"class\" + 0.007*\"tree\" + 0.006*\"mixture\" + 0.006*\"sample\" + 0.005*\"estimate\" + 0.005*\"classification\" + 0.005*\"density\" + 0.005*\"em\" + 0.004*\"likelihood\" + 0.004*\"prediction\"\n",
      "2020-04-04 03:02:33,434 : INFO : topic #9 (0.051): 0.024*\"image\" + 0.009*\"object\" + 0.008*\"chip\" + 0.007*\"circuit\" + 0.006*\"analog\" + 0.005*\"recognition\" + 0.005*\"distance\" + 0.005*\"pixel\" + 0.005*\"face\" + 0.004*\"visual\"\n",
      "2020-04-04 03:02:33,435 : INFO : topic #8 (0.051): 0.009*\"gaussian\" + 0.008*\"noise\" + 0.006*\"matrix\" + 0.006*\"hidden\" + 0.005*\"component\" + 0.005*\"variance\" + 0.004*\"basis\" + 0.004*\"approximation\" + 0.004*\"kernel\" + 0.004*\"prior\"\n",
      "2020-04-04 03:02:33,436 : INFO : topic diff=0.149888, rho=0.301511\n",
      "2020-04-04 03:02:33,445 : INFO : PROGRESS: pass 10, at document #1740/1740\n",
      "2020-04-04 03:02:40,284 : INFO : optimized alpha [0.03698007, 0.043574803, 0.04033291, 0.043047693, 0.03940426, 0.04920922, 0.045666903, 0.03582059, 0.051430583, 0.050397776]\n",
      "2020-04-04 03:02:40,292 : INFO : topic #7 (0.036): 0.017*\"speech\" + 0.016*\"recognition\" + 0.015*\"word\" + 0.011*\"classifier\" + 0.009*\"hidden\" + 0.008*\"class\" + 0.007*\"sequence\" + 0.007*\"context\" + 0.007*\"layer\" + 0.006*\"speaker\"\n",
      "2020-04-04 03:02:40,294 : INFO : topic #0 (0.037): 0.013*\"signal\" + 0.011*\"cell\" + 0.008*\"response\" + 0.007*\"direction\" + 0.007*\"frequency\" + 0.007*\"noise\" + 0.007*\"visual\" + 0.006*\"stimulus\" + 0.006*\"correlation\" + 0.006*\"filter\"\n",
      "2020-04-04 03:02:40,295 : INFO : topic #5 (0.049): 0.008*\"class\" + 0.007*\"tree\" + 0.006*\"mixture\" + 0.006*\"sample\" + 0.005*\"estimate\" + 0.005*\"classification\" + 0.005*\"density\" + 0.005*\"em\" + 0.004*\"likelihood\" + 0.004*\"prediction\"\n",
      "2020-04-04 03:02:40,296 : INFO : topic #9 (0.050): 0.025*\"image\" + 0.009*\"object\" + 0.008*\"chip\" + 0.007*\"circuit\" + 0.006*\"analog\" + 0.005*\"recognition\" + 0.005*\"pixel\" + 0.005*\"distance\" + 0.005*\"face\" + 0.004*\"visual\"\n",
      "2020-04-04 03:02:40,297 : INFO : topic #8 (0.051): 0.009*\"gaussian\" + 0.008*\"noise\" + 0.006*\"matrix\" + 0.006*\"hidden\" + 0.005*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"basis\" + 0.004*\"kernel\" + 0.004*\"prior\"\n",
      "2020-04-04 03:02:40,298 : INFO : topic diff=0.143084, rho=0.288675\n",
      "2020-04-04 03:02:40,312 : INFO : PROGRESS: pass 11, at document #1740/1740\n",
      "2020-04-04 03:02:46,852 : INFO : optimized alpha [0.036601894, 0.043054894, 0.0400422, 0.043397043, 0.039218184, 0.04931755, 0.046199065, 0.036126506, 0.051925756, 0.05021393]\n",
      "2020-04-04 03:02:46,860 : INFO : topic #7 (0.036): 0.017*\"speech\" + 0.016*\"recognition\" + 0.015*\"word\" + 0.011*\"classifier\" + 0.009*\"hidden\" + 0.008*\"class\" + 0.007*\"sequence\" + 0.007*\"layer\" + 0.007*\"context\" + 0.006*\"speaker\"\n",
      "2020-04-04 03:02:46,861 : INFO : topic #0 (0.037): 0.013*\"signal\" + 0.011*\"cell\" + 0.008*\"response\" + 0.007*\"frequency\" + 0.007*\"direction\" + 0.007*\"visual\" + 0.007*\"noise\" + 0.007*\"stimulus\" + 0.006*\"filter\" + 0.006*\"correlation\"\n",
      "2020-04-04 03:02:46,862 : INFO : topic #5 (0.049): 0.008*\"class\" + 0.007*\"tree\" + 0.007*\"mixture\" + 0.006*\"sample\" + 0.005*\"estimate\" + 0.005*\"classification\" + 0.005*\"density\" + 0.005*\"em\" + 0.005*\"likelihood\" + 0.004*\"prediction\"\n",
      "2020-04-04 03:02:46,862 : INFO : topic #9 (0.050): 0.026*\"image\" + 0.009*\"object\" + 0.008*\"chip\" + 0.007*\"circuit\" + 0.006*\"analog\" + 0.006*\"recognition\" + 0.005*\"pixel\" + 0.005*\"distance\" + 0.005*\"face\" + 0.004*\"voltage\"\n",
      "2020-04-04 03:02:46,863 : INFO : topic #8 (0.052): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.006*\"matrix\" + 0.006*\"hidden\" + 0.005*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"basis\" + 0.004*\"kernel\" + 0.004*\"prior\"\n",
      "2020-04-04 03:02:46,864 : INFO : topic diff=0.136162, rho=0.277350\n",
      "2020-04-04 03:02:46,871 : INFO : PROGRESS: pass 12, at document #1740/1740\n",
      "2020-04-04 03:02:52,801 : INFO : optimized alpha [0.036350705, 0.04266077, 0.03984825, 0.043824974, 0.039136965, 0.04949816, 0.04677513, 0.036439832, 0.052542374, 0.050147176]\n",
      "2020-04-04 03:02:52,809 : INFO : topic #0 (0.036): 0.013*\"signal\" + 0.011*\"cell\" + 0.008*\"response\" + 0.008*\"frequency\" + 0.007*\"visual\" + 0.007*\"direction\" + 0.007*\"stimulus\" + 0.007*\"noise\" + 0.007*\"filter\" + 0.006*\"motion\"\n",
      "2020-04-04 03:02:52,811 : INFO : topic #7 (0.036): 0.017*\"speech\" + 0.017*\"recognition\" + 0.016*\"word\" + 0.012*\"classifier\" + 0.009*\"hidden\" + 0.008*\"class\" + 0.007*\"sequence\" + 0.007*\"layer\" + 0.007*\"context\" + 0.006*\"speaker\"\n",
      "2020-04-04 03:02:52,812 : INFO : topic #5 (0.049): 0.008*\"class\" + 0.007*\"tree\" + 0.007*\"mixture\" + 0.006*\"sample\" + 0.005*\"estimate\" + 0.005*\"classification\" + 0.005*\"density\" + 0.005*\"em\" + 0.005*\"likelihood\" + 0.004*\"prediction\"\n",
      "2020-04-04 03:02:52,813 : INFO : topic #9 (0.050): 0.026*\"image\" + 0.009*\"object\" + 0.008*\"chip\" + 0.007*\"circuit\" + 0.006*\"analog\" + 0.006*\"pixel\" + 0.006*\"recognition\" + 0.005*\"distance\" + 0.005*\"face\" + 0.004*\"voltage\"\n",
      "2020-04-04 03:02:52,815 : INFO : topic #8 (0.053): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.006*\"matrix\" + 0.006*\"hidden\" + 0.005*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"basis\" + 0.004*\"kernel\" + 0.004*\"gradient\"\n",
      "2020-04-04 03:02:52,816 : INFO : topic diff=0.129283, rho=0.267261\n",
      "2020-04-04 03:02:52,824 : INFO : PROGRESS: pass 13, at document #1740/1740\n",
      "2020-04-04 03:02:58,570 : INFO : optimized alpha [0.036199637, 0.042377204, 0.039728355, 0.044330556, 0.03910633, 0.049785174, 0.047364186, 0.036754128, 0.053187177, 0.05017129]\n",
      "2020-04-04 03:02:58,578 : INFO : topic #0 (0.036): 0.014*\"signal\" + 0.010*\"cell\" + 0.008*\"response\" + 0.008*\"frequency\" + 0.008*\"visual\" + 0.008*\"stimulus\" + 0.008*\"direction\" + 0.007*\"filter\" + 0.007*\"noise\" + 0.007*\"motion\"\n",
      "2020-04-04 03:02:58,581 : INFO : topic #7 (0.037): 0.018*\"speech\" + 0.017*\"recognition\" + 0.016*\"word\" + 0.012*\"classifier\" + 0.009*\"hidden\" + 0.008*\"class\" + 0.007*\"sequence\" + 0.007*\"layer\" + 0.007*\"context\" + 0.006*\"classification\"\n",
      "2020-04-04 03:02:58,582 : INFO : topic #5 (0.050): 0.008*\"class\" + 0.007*\"tree\" + 0.007*\"mixture\" + 0.006*\"sample\" + 0.005*\"classification\" + 0.005*\"estimate\" + 0.005*\"density\" + 0.005*\"em\" + 0.005*\"likelihood\" + 0.004*\"prediction\"\n",
      "2020-04-04 03:02:58,583 : INFO : topic #9 (0.050): 0.027*\"image\" + 0.009*\"object\" + 0.008*\"chip\" + 0.008*\"circuit\" + 0.006*\"analog\" + 0.006*\"pixel\" + 0.006*\"recognition\" + 0.005*\"distance\" + 0.005*\"face\" + 0.004*\"voltage\"\n",
      "2020-04-04 03:02:58,584 : INFO : topic #8 (0.053): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.006*\"matrix\" + 0.006*\"hidden\" + 0.005*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"basis\" + 0.004*\"gradient\" + 0.004*\"kernel\"\n",
      "2020-04-04 03:02:58,585 : INFO : topic diff=0.122498, rho=0.258199\n",
      "2020-04-04 03:02:58,593 : INFO : PROGRESS: pass 14, at document #1740/1740\n",
      "2020-04-04 03:03:04,271 : INFO : optimized alpha [0.036128573, 0.042208977, 0.039671123, 0.044879057, 0.039170336, 0.050133515, 0.047990743, 0.037072066, 0.053868122, 0.050282843]\n",
      "2020-04-04 03:03:04,280 : INFO : topic #0 (0.036): 0.014*\"signal\" + 0.010*\"cell\" + 0.009*\"response\" + 0.009*\"frequency\" + 0.008*\"visual\" + 0.008*\"stimulus\" + 0.008*\"direction\" + 0.008*\"filter\" + 0.007*\"motion\" + 0.007*\"noise\"\n",
      "2020-04-04 03:03:04,280 : INFO : topic #7 (0.037): 0.018*\"speech\" + 0.017*\"recognition\" + 0.016*\"word\" + 0.012*\"classifier\" + 0.009*\"hidden\" + 0.008*\"class\" + 0.007*\"sequence\" + 0.007*\"layer\" + 0.007*\"context\" + 0.007*\"classification\"\n",
      "2020-04-04 03:03:04,280 : INFO : topic #5 (0.050): 0.008*\"class\" + 0.007*\"tree\" + 0.007*\"mixture\" + 0.006*\"sample\" + 0.005*\"classification\" + 0.005*\"estimate\" + 0.005*\"density\" + 0.005*\"em\" + 0.005*\"likelihood\" + 0.004*\"prediction\"\n",
      "2020-04-04 03:03:04,280 : INFO : topic #9 (0.050): 0.027*\"image\" + 0.009*\"object\" + 0.008*\"chip\" + 0.008*\"circuit\" + 0.006*\"analog\" + 0.006*\"pixel\" + 0.006*\"recognition\" + 0.005*\"distance\" + 0.005*\"face\" + 0.004*\"voltage\"\n",
      "2020-04-04 03:03:04,284 : INFO : topic #8 (0.054): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.006*\"matrix\" + 0.006*\"hidden\" + 0.005*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"basis\" + 0.004*\"gradient\" + 0.004*\"kernel\"\n",
      "2020-04-04 03:03:04,285 : INFO : topic diff=0.115875, rho=0.250000\n",
      "2020-04-04 03:03:04,291 : INFO : PROGRESS: pass 15, at document #1740/1740\n",
      "2020-04-04 03:03:09,813 : INFO : optimized alpha [0.0361267, 0.042124733, 0.039656017, 0.04550354, 0.039276566, 0.050512284, 0.04867548, 0.037399475, 0.0545656, 0.050494533]\n",
      "2020-04-04 03:03:09,821 : INFO : topic #0 (0.036): 0.014*\"signal\" + 0.010*\"cell\" + 0.009*\"response\" + 0.009*\"frequency\" + 0.009*\"visual\" + 0.008*\"stimulus\" + 0.008*\"filter\" + 0.008*\"motion\" + 0.008*\"direction\" + 0.007*\"noise\"\n",
      "2020-04-04 03:03:09,821 : INFO : topic #7 (0.037): 0.018*\"speech\" + 0.017*\"recognition\" + 0.016*\"word\" + 0.012*\"classifier\" + 0.009*\"hidden\" + 0.009*\"class\" + 0.007*\"sequence\" + 0.007*\"layer\" + 0.007*\"context\" + 0.007*\"classification\"\n",
      "2020-04-04 03:03:09,821 : INFO : topic #9 (0.050): 0.028*\"image\" + 0.009*\"object\" + 0.008*\"chip\" + 0.008*\"circuit\" + 0.006*\"analog\" + 0.006*\"pixel\" + 0.006*\"recognition\" + 0.005*\"distance\" + 0.005*\"face\" + 0.004*\"voltage\"\n",
      "2020-04-04 03:03:09,825 : INFO : topic #5 (0.051): 0.008*\"class\" + 0.007*\"tree\" + 0.007*\"mixture\" + 0.006*\"sample\" + 0.005*\"classification\" + 0.005*\"estimate\" + 0.005*\"em\" + 0.005*\"density\" + 0.005*\"likelihood\" + 0.004*\"log\"\n",
      "2020-04-04 03:03:09,826 : INFO : topic #8 (0.055): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.007*\"matrix\" + 0.006*\"hidden\" + 0.006*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"basis\" + 0.005*\"gradient\" + 0.004*\"kernel\"\n",
      "2020-04-04 03:03:09,827 : INFO : topic diff=0.109468, rho=0.242536\n",
      "2020-04-04 03:03:09,834 : INFO : PROGRESS: pass 16, at document #1740/1740\n",
      "2020-04-04 03:03:15,416 : INFO : optimized alpha [0.036179516, 0.042069893, 0.039731868, 0.046162732, 0.03941338, 0.050909553, 0.049435854, 0.03772496, 0.055296004, 0.050715577]\n",
      "2020-04-04 03:03:15,425 : INFO : topic #0 (0.036): 0.014*\"signal\" + 0.010*\"cell\" + 0.009*\"response\" + 0.009*\"frequency\" + 0.009*\"visual\" + 0.009*\"stimulus\" + 0.008*\"filter\" + 0.008*\"motion\" + 0.008*\"direction\" + 0.007*\"noise\"\n",
      "2020-04-04 03:03:15,427 : INFO : topic #7 (0.038): 0.018*\"speech\" + 0.018*\"recognition\" + 0.017*\"word\" + 0.012*\"classifier\" + 0.009*\"hidden\" + 0.009*\"class\" + 0.008*\"sequence\" + 0.007*\"layer\" + 0.007*\"context\" + 0.007*\"classification\"\n",
      "2020-04-04 03:03:15,428 : INFO : topic #9 (0.051): 0.028*\"image\" + 0.009*\"object\" + 0.008*\"chip\" + 0.008*\"circuit\" + 0.006*\"analog\" + 0.006*\"pixel\" + 0.006*\"recognition\" + 0.006*\"distance\" + 0.005*\"face\" + 0.004*\"voltage\"\n",
      "2020-04-04 03:03:15,429 : INFO : topic #5 (0.051): 0.009*\"class\" + 0.007*\"tree\" + 0.007*\"mixture\" + 0.006*\"sample\" + 0.006*\"classification\" + 0.005*\"estimate\" + 0.005*\"em\" + 0.005*\"density\" + 0.005*\"likelihood\" + 0.004*\"log\"\n",
      "2020-04-04 03:03:15,429 : INFO : topic #8 (0.055): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.007*\"matrix\" + 0.006*\"hidden\" + 0.006*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"gradient\" + 0.005*\"basis\" + 0.004*\"kernel\"\n",
      "2020-04-04 03:03:15,430 : INFO : topic diff=0.103416, rho=0.235702\n",
      "2020-04-04 03:03:15,438 : INFO : PROGRESS: pass 17, at document #1740/1740\n",
      "2020-04-04 03:03:21,270 : INFO : optimized alpha [0.036298066, 0.042077743, 0.039877817, 0.04687953, 0.039568555, 0.05135096, 0.050279826, 0.03805625, 0.056085955, 0.05097109]\n",
      "2020-04-04 03:03:21,277 : INFO : topic #0 (0.036): 0.014*\"signal\" + 0.009*\"cell\" + 0.009*\"response\" + 0.009*\"frequency\" + 0.009*\"visual\" + 0.009*\"stimulus\" + 0.009*\"filter\" + 0.009*\"motion\" + 0.008*\"direction\" + 0.007*\"noise\"\n",
      "2020-04-04 03:03:21,280 : INFO : topic #7 (0.038): 0.018*\"speech\" + 0.018*\"recognition\" + 0.017*\"word\" + 0.012*\"classifier\" + 0.009*\"hidden\" + 0.009*\"class\" + 0.008*\"sequence\" + 0.008*\"layer\" + 0.007*\"context\" + 0.007*\"classification\"\n",
      "2020-04-04 03:03:21,283 : INFO : topic #9 (0.051): 0.029*\"image\" + 0.009*\"object\" + 0.009*\"chip\" + 0.008*\"circuit\" + 0.006*\"analog\" + 0.006*\"pixel\" + 0.006*\"recognition\" + 0.006*\"distance\" + 0.005*\"face\" + 0.004*\"voltage\"\n",
      "2020-04-04 03:03:21,287 : INFO : topic #5 (0.051): 0.009*\"class\" + 0.007*\"tree\" + 0.007*\"mixture\" + 0.006*\"sample\" + 0.006*\"classification\" + 0.005*\"estimate\" + 0.005*\"em\" + 0.005*\"likelihood\" + 0.005*\"density\" + 0.004*\"log\"\n",
      "2020-04-04 03:03:21,290 : INFO : topic #8 (0.056): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.007*\"matrix\" + 0.006*\"hidden\" + 0.006*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"gradient\" + 0.005*\"basis\" + 0.004*\"kernel\"\n",
      "2020-04-04 03:03:21,292 : INFO : topic diff=0.097680, rho=0.229416\n",
      "2020-04-04 03:03:21,300 : INFO : PROGRESS: pass 18, at document #1740/1740\n",
      "2020-04-04 03:03:27,625 : INFO : optimized alpha [0.03649629, 0.042128745, 0.040045284, 0.04768358, 0.039772857, 0.051809605, 0.051165134, 0.03838209, 0.056898385, 0.051234055]\n",
      "2020-04-04 03:03:27,635 : INFO : topic #0 (0.036): 0.014*\"signal\" + 0.010*\"response\" + 0.009*\"frequency\" + 0.009*\"visual\" + 0.009*\"stimulus\" + 0.009*\"cell\" + 0.009*\"filter\" + 0.009*\"motion\" + 0.008*\"direction\" + 0.007*\"noise\"\n",
      "2020-04-04 03:03:27,636 : INFO : topic #7 (0.038): 0.018*\"speech\" + 0.018*\"recognition\" + 0.017*\"word\" + 0.012*\"classifier\" + 0.009*\"hidden\" + 0.009*\"class\" + 0.008*\"layer\" + 0.008*\"sequence\" + 0.007*\"context\" + 0.007*\"classification\"\n",
      "2020-04-04 03:03:27,637 : INFO : topic #9 (0.051): 0.029*\"image\" + 0.009*\"object\" + 0.009*\"chip\" + 0.008*\"circuit\" + 0.006*\"analog\" + 0.006*\"pixel\" + 0.006*\"recognition\" + 0.006*\"distance\" + 0.005*\"face\" + 0.005*\"voltage\"\n",
      "2020-04-04 03:03:27,637 : INFO : topic #5 (0.052): 0.009*\"class\" + 0.008*\"tree\" + 0.007*\"mixture\" + 0.006*\"sample\" + 0.006*\"classification\" + 0.005*\"estimate\" + 0.005*\"em\" + 0.005*\"likelihood\" + 0.005*\"density\" + 0.004*\"log\"\n",
      "2020-04-04 03:03:27,640 : INFO : topic #8 (0.057): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.007*\"matrix\" + 0.006*\"hidden\" + 0.006*\"component\" + 0.005*\"variance\" + 0.005*\"approximation\" + 0.005*\"gradient\" + 0.005*\"basis\" + 0.004*\"kernel\"\n",
      "2020-04-04 03:03:27,641 : INFO : topic diff=0.092310, rho=0.223607\n",
      "2020-04-04 03:03:27,652 : INFO : PROGRESS: pass 19, at document #1740/1740\n",
      "2020-04-04 03:03:34,255 : INFO : optimized alpha [0.03673557, 0.042199794, 0.04024776, 0.048486743, 0.03997704, 0.052289322, 0.05207321, 0.038702942, 0.0577287, 0.051523358]\n",
      "2020-04-04 03:03:34,265 : INFO : topic #0 (0.037): 0.015*\"signal\" + 0.010*\"response\" + 0.010*\"visual\" + 0.010*\"frequency\" + 0.010*\"stimulus\" + 0.009*\"motion\" + 0.009*\"filter\" + 0.009*\"cell\" + 0.008*\"direction\" + 0.007*\"noise\"\n",
      "2020-04-04 03:03:34,266 : INFO : topic #7 (0.039): 0.018*\"speech\" + 0.018*\"recognition\" + 0.017*\"word\" + 0.012*\"classifier\" + 0.009*\"hidden\" + 0.009*\"class\" + 0.008*\"layer\" + 0.008*\"sequence\" + 0.007*\"classification\" + 0.007*\"context\"\n",
      "2020-04-04 03:03:34,268 : INFO : topic #6 (0.052): 0.009*\"neuron\" + 0.008*\"matrix\" + 0.007*\"memory\" + 0.007*\"dynamic\" + 0.007*\"field\" + 0.006*\"solution\" + 0.005*\"energy\" + 0.005*\"threshold\" + 0.005*\"node\" + 0.004*\"net\"\n",
      "2020-04-04 03:03:34,269 : INFO : topic #5 (0.052): 0.009*\"class\" + 0.008*\"tree\" + 0.007*\"mixture\" + 0.007*\"sample\" + 0.006*\"classification\" + 0.005*\"estimate\" + 0.005*\"em\" + 0.005*\"likelihood\" + 0.005*\"density\" + 0.004*\"log\"\n",
      "2020-04-04 03:03:34,269 : INFO : topic #8 (0.058): 0.009*\"gaussian\" + 0.009*\"noise\" + 0.007*\"matrix\" + 0.006*\"hidden\" + 0.006*\"component\" + 0.005*\"variance\" + 0.005*\"gradient\" + 0.005*\"approximation\" + 0.005*\"basis\" + 0.004*\"kernel\"\n",
      "2020-04-04 03:03:34,273 : INFO : topic diff=0.087261, rho=0.218218\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-04 03:32:31,175 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -1.1425.\n",
      "[([(0.028793693, 'neuron'),\n",
      "   (0.022642607, 'cell'),\n",
      "   (0.010809706, 'spike'),\n",
      "   (0.009854929, 'synaptic'),\n",
      "   (0.008547382, 'response'),\n",
      "   (0.008156084, 'firing'),\n",
      "   (0.00758412, 'activity'),\n",
      "   (0.00688931, 'stimulus'),\n",
      "   (0.0059619662, 'cortex'),\n",
      "   (0.0053345696, 'connection'),\n",
      "   (0.00524123, 'cortical'),\n",
      "   (0.005093992, 'synapsis'),\n",
      "   (0.004970271, 'potential'),\n",
      "   (0.004401905, 'eye'),\n",
      "   (0.004251009, 'visual'),\n",
      "   (0.004098996, 'excitatory'),\n",
      "   (0.0040566763, 'fig'),\n",
      "   (0.003994026, 'simulation'),\n",
      "   (0.003938817, 'inhibitory'),\n",
      "   (0.0037402848, 'membrane')],\n",
      "  -1.0023086277887965),\n",
      " ([(0.009107464, 'gaussian'),\n",
      "   (0.008594286, 'noise'),\n",
      "   (0.0069100163, 'matrix'),\n",
      "   (0.006216657, 'hidden'),\n",
      "   (0.005711329, 'component'),\n",
      "   (0.005148847, 'variance'),\n",
      "   (0.005119954, 'gradient'),\n",
      "   (0.0050586103, 'approximation'),\n",
      "   (0.004775047, 'basis'),\n",
      "   (0.004251041, 'kernel'),\n",
      "   (0.0041522267, 'dimensional'),\n",
      "   (0.00394055, 'density'),\n",
      "   (0.003935178, 'regression'),\n",
      "   (0.0039257235, 'prior'),\n",
      "   (0.003681055, 'generalization'),\n",
      "   (0.0036719763, 'estimate'),\n",
      "   (0.0035736037, 'nonlinear'),\n",
      "   (0.003455108, 'prediction'),\n",
      "   (0.0034266673, 'optimal'),\n",
      "   (0.0033993106, 'covariance')],\n",
      "  -1.004051595390617),\n",
      " ([(0.009209068, 'policy'),\n",
      "   (0.009180841, 'action'),\n",
      "   (0.00899226, 'optimal'),\n",
      "   (0.007123135, 'bound'),\n",
      "   (0.0062291157, 'let'),\n",
      "   (0.005913082, 'theorem'),\n",
      "   (0.0051386133, 'convergence'),\n",
      "   (0.0051340987, 'approximation'),\n",
      "   (0.0048074885, 'reinforcement'),\n",
      "   (0.004303203, 'control'),\n",
      "   (0.0041679316, 'class'),\n",
      "   (0.0041526314, 'solution'),\n",
      "   (0.0040495037, 'dimension'),\n",
      "   (0.003983901, 'generalization'),\n",
      "   (0.0039029554, 'reward'),\n",
      "   (0.0036699038, 'decision'),\n",
      "   (0.0034360664, 'proof'),\n",
      "   (0.003391208, 'cost'),\n",
      "   (0.0032116876, 'dynamic'),\n",
      "   (0.0031125194, 'stochastic')],\n",
      "  -1.0771915746643161),\n",
      " ([(0.014520552, 'signal'),\n",
      "   (0.009690869, 'response'),\n",
      "   (0.009616025, 'visual'),\n",
      "   (0.009573387, 'frequency'),\n",
      "   (0.009561582, 'stimulus'),\n",
      "   (0.008987399, 'motion'),\n",
      "   (0.008982743, 'filter'),\n",
      "   (0.008974492, 'cell'),\n",
      "   (0.007868616, 'direction'),\n",
      "   (0.007253018, 'noise'),\n",
      "   (0.005547973, 'correlation'),\n",
      "   (0.0052705067, 'spatial'),\n",
      "   (0.0051606554, 'temporal'),\n",
      "   (0.0050781844, 'auditory'),\n",
      "   (0.005042581, 'activity'),\n",
      "   (0.005032255, 'channel'),\n",
      "   (0.004946131, 'sound'),\n",
      "   (0.004914035, 'component'),\n",
      "   (0.0047013443, 'phase'),\n",
      "   (0.004492217, 'field')],\n",
      "  -1.1294213117745584),\n",
      " ([(0.0097582815, 'rule'),\n",
      "   (0.008745238, 'hidden'),\n",
      "   (0.006764128, 'net'),\n",
      "   (0.004611743, 'trained'),\n",
      "   (0.004472002, 'recurrent'),\n",
      "   (0.00416343, 'learn'),\n",
      "   (0.0040672016, 'prediction'),\n",
      "   (0.0037416767, 'layer'),\n",
      "   (0.0037264798, 'architecture'),\n",
      "   (0.0036879752, 'sequence'),\n",
      "   (0.0034054106, 'activation'),\n",
      "   (0.0034050818, 'table'),\n",
      "   (0.00335962, 'learned'),\n",
      "   (0.0033555601, 'target'),\n",
      "   (0.0033425225, 'memory'),\n",
      "   (0.003139332, 'initial'),\n",
      "   (0.0030884498, 'string'),\n",
      "   (0.003009347, 'knowledge'),\n",
      "   (0.0029363704, 'language'),\n",
      "   (0.0029258488, 'connectionist')],\n",
      "  -1.1385760700510572),\n",
      " ([(0.015234497, 'control'),\n",
      "   (0.010708096, 'layer'),\n",
      "   (0.0088764215, 'object'),\n",
      "   (0.0077040917, 'field'),\n",
      "   (0.0069961655, 'motor'),\n",
      "   (0.0066102007, 'module'),\n",
      "   (0.0059680855, 'position'),\n",
      "   (0.0059494684, 'movement'),\n",
      "   (0.005861873, 'trajectory'),\n",
      "   (0.0057984767, 'controller'),\n",
      "   (0.005602458, 'dynamic'),\n",
      "   (0.0055123977, 'connection'),\n",
      "   (0.005155975, 'architecture'),\n",
      "   (0.004746628, 'forward'),\n",
      "   (0.004382705, 'character'),\n",
      "   (0.0043449216, 'activation'),\n",
      "   (0.004307024, 'feedback'),\n",
      "   (0.0041653793, 'hand'),\n",
      "   (0.004017673, 'net'),\n",
      "   (0.0039596376, 'map')],\n",
      "  -1.175933077833514),\n",
      " ([(0.029229823, 'image'),\n",
      "   (0.0093255, 'object'),\n",
      "   (0.008733178, 'chip'),\n",
      "   (0.0081733335, 'circuit'),\n",
      "   (0.0064667873, 'pixel'),\n",
      "   (0.0064594112, 'analog'),\n",
      "   (0.0057671685, 'recognition'),\n",
      "   (0.0056618066, 'distance'),\n",
      "   (0.005525984, 'face'),\n",
      "   (0.00456512, 'voltage'),\n",
      "   (0.004236927, 'view'),\n",
      "   (0.0039264136, 'vlsi'),\n",
      "   (0.0036816096, 'visual'),\n",
      "   (0.003583961, 'implementation'),\n",
      "   (0.003581052, 'vision'),\n",
      "   (0.00334021, 'scale'),\n",
      "   (0.0033106257, 'map'),\n",
      "   (0.0032213046, 'motion'),\n",
      "   (0.0030809857, 'edge'),\n",
      "   (0.003076738, 'region')],\n",
      "  -1.2027408347470627),\n",
      " ([(0.018411094, 'speech'),\n",
      "   (0.018372398, 'recognition'),\n",
      "   (0.016981404, 'word'),\n",
      "   (0.012319617, 'classifier'),\n",
      "   (0.00884681, 'hidden'),\n",
      "   (0.0088187205, 'class'),\n",
      "   (0.007766877, 'layer'),\n",
      "   (0.0076388377, 'sequence'),\n",
      "   (0.007321592, 'classification'),\n",
      "   (0.007218342, 'context'),\n",
      "   (0.0066166623, 'speaker'),\n",
      "   (0.0065446915, 'hmm'),\n",
      "   (0.0060228864, 'trained'),\n",
      "   (0.005623248, 'signal'),\n",
      "   (0.004975897, 'mlp'),\n",
      "   (0.0047672144, 'frame'),\n",
      "   (0.004723192, 'architecture'),\n",
      "   (0.0045549814, 'net'),\n",
      "   (0.004505595, 'phoneme'),\n",
      "   (0.0044598524, 'acoustic')],\n",
      "  -1.2258417613698667),\n",
      " ([(0.009320575, 'neuron'),\n",
      "   (0.0076746573, 'matrix'),\n",
      "   (0.007320193, 'memory'),\n",
      "   (0.0071327058, 'dynamic'),\n",
      "   (0.006501183, 'field'),\n",
      "   (0.0055900957, 'solution'),\n",
      "   (0.0051763454, 'energy'),\n",
      "   (0.004615235, 'threshold'),\n",
      "   (0.0045435186, 'node'),\n",
      "   (0.0039655343, 'net'),\n",
      "   (0.0039632786, 'hopfield'),\n",
      "   (0.00385511, 'capacity'),\n",
      "   (0.0035435327, 'graph'),\n",
      "   (0.0034291188, 'rule'),\n",
      "   (0.0033420385, 'attractor'),\n",
      "   (0.0033312405, 'constraint'),\n",
      "   (0.003318967, 'eq'),\n",
      "   (0.0032080545, 'let'),\n",
      "   (0.0031461292, 'connection'),\n",
      "   (0.0029347944, 'element')],\n",
      "  -1.232187766402003),\n",
      " ([(0.008900662, 'class'),\n",
      "   (0.007578614, 'tree'),\n",
      "   (0.0069092643, 'mixture'),\n",
      "   (0.006511163, 'sample'),\n",
      "   (0.0057072733, 'classification'),\n",
      "   (0.005453655, 'estimate'),\n",
      "   (0.004902749, 'em'),\n",
      "   (0.004852595, 'likelihood'),\n",
      "   (0.004733166, 'density'),\n",
      "   (0.0042396337, 'log'),\n",
      "   (0.0040179472, 'expert'),\n",
      "   (0.003984215, 'prediction'),\n",
      "   (0.0039781677, 'classifier'),\n",
      "   (0.0038730425, 'node'),\n",
      "   (0.0037486947, 'estimation'),\n",
      "   (0.00374224, 'loss'),\n",
      "   (0.0037098587, 'bayesian'),\n",
      "   (0.0036713032, 'cluster'),\n",
      "   (0.0035952234, 'prior'),\n",
      "   (0.0034771317, 'decision')],\n",
      "  -1.2368855984074107)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
